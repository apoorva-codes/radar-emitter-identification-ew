{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e5df179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Found: PDW_data.parquet\n",
      "  Emitter_ID    TOA_us  Freq_MHz  PW_us  Amplitude  Power_dBm  AC_Lat  \\\n",
      "0    Radar_3   262.079   9051.28   5.03   0.004693     -16.57    12.0   \n",
      "1    Radar_0   831.823   9100.10   5.02   0.001586     -26.00    12.0   \n",
      "2    Radar_3   862.444   9050.63   5.03   0.004732     -16.50    12.0   \n",
      "3    Radar_2  1118.014   9000.72   7.99   0.001480     -26.60    12.0   \n",
      "4    Radar_1  1181.078   9050.51   5.04   0.001469     -26.66    12.0   \n",
      "\n",
      "      AC_Lon     DOA_deg    Range_m  \n",
      "0  76.500000  354.555952   55937.57  \n",
      "1  76.500001    3.809488  167350.52  \n",
      "2  76.500003  355.359951   55937.26  \n",
      "3  76.500002    5.328868  178892.74  \n",
      "4  76.500003    5.352844  178892.71  \n"
     ]
    }
   ],
   "source": [
    "# CELL 1: VERIFY LOCAL PDW FILE\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "FILE_PATH = Path(\"PDW_data.parquet\")\n",
    "\n",
    "if not FILE_PATH.is_file():\n",
    "    raise FileNotFoundError(f\"File not found: {FILE_PATH}\")\n",
    "\n",
    "print(f\"File Found: {FILE_PATH}\")\n",
    "df=pd.read_parquet(FILE_PATH)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5bd2489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processing setup ready.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "BATCH_SIZE = 10000\n",
    "STORE_PATH = \"pdw_feature_store.parquet\"\n",
    "\n",
    "REQ_COLS = [\"TOA_us\", \"PW_us\", \"Freq_MHz\", \"Power_dBm\", \"DOA_deg\", \"AC_Lat\", \"AC_Lon\"]\n",
    "\n",
    "print(\"Batch processing setup ready.\")\n",
    "\n",
    "\n",
    "def clean_batch(df):\n",
    "    # Convert only required columns at once\n",
    "    df[REQ_COLS] = df[REQ_COLS].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "    # Build ONE mask\n",
    "    mask = (\n",
    "        (df[\"TOA_us\"].values >= 0) &\n",
    "        (df[\"PW_us\"].values > 0) &\n",
    "        (df[\"Freq_MHz\"].values > 0)\n",
    "    )\n",
    "\n",
    "    df = df.loc[mask]\n",
    "\n",
    "    # Drop rows with NaNs only in required columns\n",
    "    df = df.dropna(subset=REQ_COLS)\n",
    "\n",
    "    # Sort by TOA (important for TOA_gap)\n",
    "    df = df.sort_values(\"TOA_us\", kind=\"mergesort\")\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def engineer_features(df):\n",
    "\n",
    "    # Work with numpy arrays\n",
    "    doa = df[\"DOA_deg\"].values\n",
    "    toa = df[\"TOA_us\"].values\n",
    "    pw = df[\"PW_us\"].values\n",
    "    power = df[\"Power_dBm\"].values\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # AOA Features (same as before)\n",
    "    # -----------------------------------------------------\n",
    "    rad = np.radians(doa)\n",
    "    df[\"AOA_sin_w\"] = np.sin(rad)\n",
    "    df[\"AOA_cos_w\"] = np.cos(rad)\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # dTOA and log_dTOA  (same as before)\n",
    "    # -----------------------------------------------------\n",
    "    dtoa = np.empty_like(toa)\n",
    "    dtoa[0] = 1e-6\n",
    "    dtoa[1:] = np.diff(toa)\n",
    "    np.clip(dtoa, 1e-6, None, out=dtoa)\n",
    "\n",
    "    df[\"log_dTOA\"] = np.log1p(dtoa)\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # NEW FEATURE: TOA_gap (raw dTOA, not logged)\n",
    "    # -----------------------------------------------------\n",
    "    # This preserves PRI information for clustering.\n",
    "    df[\"TOA_gap\"] = dtoa.astype(np.float32)\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # PW, Power logs\n",
    "    # -----------------------------------------------------\n",
    "    df[\"log_PW\"] = np.log1p(pw)\n",
    "\n",
    "    min_power = power.min()\n",
    "    df[\"log_Power\"] = np.log1p(power - min_power + 1)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd048215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting batch processing from Parquet...\n",
      "Processing row group 1/2\n",
      "Processing row group 2/2\n",
      "\n",
      "CELL 2 COMPLETE: Features Stored.\n",
      "Feature store saved to: pdw_feature_store.parquet\n",
      "Total pulses processed: 1895990\n"
     ]
    }
   ],
   "source": [
    "# CELL 2B: EXECUTE BATCH PROCESSING\n",
    "\n",
    "print(\"Starting batch processing from Parquet...\")\n",
    "\n",
    "running_sum = None\n",
    "running_sq = None\n",
    "running_count = 0\n",
    "writer = None\n",
    "\n",
    "# -----------------------------\n",
    "# UPDATED FEATURE LIST\n",
    "# -----------------------------\n",
    "FEATURE_COLS = [\n",
    "    \"Freq_MHz\",\n",
    "    \"AOA_sin_w\",\n",
    "    \"AOA_cos_w\",\n",
    "    \"log_PW\",\n",
    "    \"log_Power\",\n",
    "    \"log_dTOA\",\n",
    "    \"TOA_gap\"      # <<— NEW TEMPORAL FEATURE\n",
    "]\n",
    "\n",
    "READ_COLS = REQ_COLS\n",
    "\n",
    "parquet_file = pq.ParquetFile(FILE_PATH)\n",
    "\n",
    "for i in range(parquet_file.num_row_groups):\n",
    "\n",
    "    print(f\"Processing row group {i+1}/{parquet_file.num_row_groups}\")\n",
    "\n",
    "    table = parquet_file.read_row_group(i, columns=READ_COLS)\n",
    "    df_batch = table.to_pandas()\n",
    "\n",
    "    df_batch = clean_batch(df_batch)\n",
    "    if df_batch.empty:\n",
    "        continue\n",
    "\n",
    "    df_batch = engineer_features(df_batch)\n",
    "\n",
    "    # Convert features to Matrix\n",
    "    X = df_batch[FEATURE_COLS].to_numpy(dtype=np.float32, copy=False)\n",
    "\n",
    "    # Running mean and std\n",
    "    batch_sum = X.sum(axis=0)\n",
    "    X_sq = X * X\n",
    "    batch_sq = X_sq.sum(axis=0)\n",
    "\n",
    "    if running_sum is None:\n",
    "        running_sum = batch_sum\n",
    "        running_sq = batch_sq\n",
    "        running_count = X.shape[0]\n",
    "    else:\n",
    "        running_sum += batch_sum\n",
    "        running_sq += batch_sq\n",
    "        running_count += X.shape[0]\n",
    "\n",
    "    # Convert back to Parquet format\n",
    "    out_table = pa.Table.from_pandas(df_batch, preserve_index=False)\n",
    "\n",
    "    # Build new parquet file\n",
    "    if writer is None:\n",
    "        writer = pq.ParquetWriter(STORE_PATH, out_table.schema)\n",
    "\n",
    "    writer.write_table(out_table)\n",
    "\n",
    "if writer:\n",
    "    writer.close()\n",
    "\n",
    "print(\"\\nCELL 2 COMPLETE: Features Stored.\")\n",
    "print(\"Feature store saved to:\", STORE_PATH)\n",
    "print(\"Total pulses processed:\", running_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4d55297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing global statistics for scaling...\n",
      "\n",
      "GLOBAL NORMALIZATION PARAMETERS:\n",
      "Mean: [9.0589863e+03 6.8318896e-02 7.2207624e-01 1.8645937e+00 1.8478618e+00\n",
      " 4.5631485e+00 1.4377835e+02]\n",
      "Std : [ 35.62655      0.21612506   0.6536271    0.15591793   0.59555817\n",
      "   1.0876029  107.682785  ]\n",
      "Total pulses counted: 1895990\n",
      "\n",
      "CELL 3 COMPLETE.\n",
      "Normalization parameters saved to: norm_params.pkl\n"
     ]
    }
   ],
   "source": [
    "# CELL 3: COMPUTE GLOBAL MEAN + STD FOR NORMALIZATION\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "print(\"Computing global statistics for scaling...\")\n",
    "\n",
    "if running_count == 0:\n",
    "    raise RuntimeError(\"No pulses were processed.\")\n",
    "\n",
    "# float64 -> Numerical Accuracy\n",
    "running_sum = running_sum.astype(np.float64, copy=False)\n",
    "running_sq = running_sq.astype(np.float64, copy=False)\n",
    "\n",
    "# Compute Mean\n",
    "global_mean = running_sum / running_count\n",
    "\n",
    "# Compute Variance safely\n",
    "global_var = (running_sq / running_count) - (global_mean * global_mean)\n",
    "\n",
    "# Prevent negative Variance\n",
    "np.maximum(global_var, 0.0, out=global_var)\n",
    "\n",
    "# Compute STD with numerical safety\n",
    "global_std = np.sqrt(global_var + 1e-9)\n",
    "\n",
    "norm_params = {\n",
    "    \"feature_cols\": FEATURE_COLS,\n",
    "    \"mean\": global_mean.astype(np.float32),\n",
    "    \"std\": global_std.astype(np.float32),\n",
    "    \"count\": running_count\n",
    "}\n",
    "\n",
    "print(\"\\nGLOBAL NORMALIZATION PARAMETERS:\")\n",
    "print(\"Mean:\", norm_params[\"mean\"])\n",
    "print(\"Std :\", norm_params[\"std\"])\n",
    "print(\"Total pulses counted:\", running_count)\n",
    "\n",
    "with open(\"norm_params.pkl\", \"wb\") as f:\n",
    "    pickle.dump(norm_params, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(\"\\nCELL 3 COMPLETE.\")\n",
    "print(\"Normalization parameters saved to: norm_params.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1af7bed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading feature store from disk...\n",
      "Feature Store Loaded. Total pulses: 1895990\n",
      "\n",
      "Normalizing features...\n",
      "Normalization complete.\n",
      "\n",
      "Applying PCA (6+1 → 4 dims)...\n",
      "PCA complete. Variance retained: 0.9128465\n",
      "\n",
      "Running HDBSCAN clustering...\n",
      "min_cluster_size: 1895\n",
      "min_samples: 43\n",
      "HDBSCAN done.\n",
      "Unique coarse clusters found: [np.int64(-1), np.int64(0), np.int64(1), np.int64(2), np.int64(3)]\n",
      "Noise pulses: 1\n",
      "\n",
      "CELL 4 COMPLETE:\n",
      "Clustered PDWs saved to: pdw_clustered.parquet\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CELL 4: HDBSCAN RF CLUSTERING (Corrected for TOA-gap Feature)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hdbscan\n",
    "import pickle\n",
    "import gc\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# ------------------------------------------\n",
    "# LOAD FEATURE STORE\n",
    "# ------------------------------------------\n",
    "\n",
    "print(\"Loading feature store from disk...\")\n",
    "df = pd.read_parquet(STORE_PATH)\n",
    "print(\"Feature Store Loaded. Total pulses:\", len(df))\n",
    "\n",
    "# ------------------------------------------\n",
    "# LOAD NORMALIZATION PARAMETERS\n",
    "# ------------------------------------------\n",
    "\n",
    "with open(\"norm_params.pkl\", \"rb\") as f:\n",
    "    norm_params = pickle.load(f)\n",
    "\n",
    "FEATURE_COLS = norm_params[\"feature_cols\"] + [\"TOA_gap\"]   # <-- ADD TEMPORAL FEATURE\n",
    "global_mean = norm_params[\"mean\"]\n",
    "global_std  = norm_params[\"std\"]\n",
    "\n",
    "# Recompute mean/std for TOA_gap dynamically\n",
    "gap_mean = df[\"TOA_gap\"].mean()\n",
    "gap_std  = df[\"TOA_gap\"].std() + 1e-6    # avoid divide by zero\n",
    "\n",
    "# ------------------------------------------\n",
    "# NORMALIZE FEATURES\n",
    "# ------------------------------------------\n",
    "\n",
    "print(\"\\nNormalizing features...\")\n",
    "\n",
    "X = df[FEATURE_COLS].to_numpy(dtype=np.float32)\n",
    "\n",
    "# Use global mean/std for original features\n",
    "# and dynamic mean/std for TOA_gap\n",
    "X_norm = X.copy()\n",
    "X_norm[:, :-1] = (X[:, :-1] - global_mean) / global_std   # original 6 features\n",
    "X_norm[:, -1]  = (X[:, -1]  - gap_mean)   / gap_std       # TOA_gap normalization\n",
    "\n",
    "print(\"Normalization complete.\")\n",
    "\n",
    "# ------------------------------------------\n",
    "# PCA FOR DIMENSION REDUCTION (optional but highly beneficial)\n",
    "# ------------------------------------------\n",
    "\n",
    "print(\"\\nApplying PCA (6+1 → 4 dims)...\")\n",
    "\n",
    "pca = PCA(n_components=4, random_state=42)\n",
    "X_pca = pca.fit_transform(X_norm)\n",
    "\n",
    "print(\"PCA complete. Variance retained:\", np.sum(pca.explained_variance_ratio_))\n",
    "\n",
    "# ------------------------------------------\n",
    "# HDBSCAN CLUSTERING (Coarse stage)\n",
    "# ------------------------------------------\n",
    "\n",
    "print(\"\\nRunning HDBSCAN clustering...\")\n",
    "\n",
    "n_samples = len(df)\n",
    "\n",
    "min_cluster_size = max(500, int(0.001 * n_samples))\n",
    "min_samples = max(10, int(np.sqrt(min_cluster_size)))\n",
    "\n",
    "print(\"min_cluster_size:\", min_cluster_size)\n",
    "print(\"min_samples:\", min_samples)\n",
    "\n",
    "clusterer = hdbscan.HDBSCAN(\n",
    "    min_cluster_size=min_cluster_size,\n",
    "    min_samples=min_samples,\n",
    "    cluster_selection_epsilon=0.5,\n",
    "    metric=\"euclidean\",\n",
    "    cluster_selection_method=\"leaf\",\n",
    "    approx_min_span_tree=True,\n",
    "    gen_min_span_tree=False,\n",
    "    core_dist_n_jobs=-1\n",
    ")\n",
    "\n",
    "labels = clusterer.fit_predict(X_pca)\n",
    "\n",
    "print(\"HDBSCAN done.\")\n",
    "print(\"Unique coarse clusters found:\", sorted(set(labels)))\n",
    "print(\"Noise pulses:\", np.sum(labels == -1))\n",
    "\n",
    "# ------------------------------------------\n",
    "# SAVE COARSE CLUSTERS\n",
    "# ------------------------------------------\n",
    "\n",
    "df[\"Coarse_Cluster\"] = labels\n",
    "\n",
    "CLUSTERED_OUTPUT = \"pdw_clustered.parquet\"\n",
    "df.to_parquet(CLUSTERED_OUTPUT, index=False)\n",
    "\n",
    "print(\"\\nCELL 4 COMPLETE:\")\n",
    "print(\"Clustered PDWs saved to:\", CLUSTERED_OUTPUT)\n",
    "\n",
    "# Memory cleanup\n",
    "del X_norm, X_pca, clusterer\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60df9334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inspecting clusters...\n",
      "\n",
      "======================================================================\n",
      "CLUSTER 0\n",
      "Total Pulses: 340753\n",
      "----------------------------------------------------------------------\n",
      "               TOA_us  PW_us  Freq_MHz  Power_dBm    DOA_deg  AC_Lat  \\\n",
      "3        1.118014e+03   7.99   9000.72     -26.60   5.328868    12.0   \n",
      "9        1.928859e+03   8.03   8998.73     -26.71   5.399738    12.0   \n",
      "14       2.729081e+03   7.95   8998.33     -26.46   5.327662    12.0   \n",
      "20       3.531189e+03   8.06   9000.40     -26.56   5.267159    12.0   \n",
      "26       4.319028e+03   8.02   8999.70     -26.68   5.330958    12.0   \n",
      "...               ...    ...       ...        ...        ...     ...   \n",
      "1895938  2.725954e+08   7.91   8998.77     -14.08  22.889325    12.0   \n",
      "1895944  2.725962e+08   8.02   9000.62     -14.07  22.983007    12.0   \n",
      "1895950  2.725970e+08   7.97   9001.41     -13.95  22.948837    12.0   \n",
      "1895955  2.725978e+08   7.94   8999.47     -14.13  23.082891    12.0   \n",
      "1895960  2.725986e+08   7.95   9001.13     -14.06  22.674282    12.0   \n",
      "\n",
      "            AC_Lon  AOA_sin_w  AOA_cos_w  log_dTOA     TOA_gap    log_PW  \\\n",
      "3        76.500002   0.092872   0.995678  5.547402  255.570007  2.196113   \n",
      "9        76.500006   0.094104   0.995562  5.005650  148.253998  2.200552   \n",
      "14       76.500010   0.092851   0.995680  5.736246  308.898987  2.191654   \n",
      "20       76.500013   0.091800   0.995777  4.221256   67.119003  2.203869   \n",
      "26       76.500017   0.092909   0.995675  4.985974  145.345993  2.199444   \n",
      "...            ...        ...        ...       ...         ...       ...   \n",
      "1895938  77.749966   0.388952   0.921258  4.611093   99.594002  2.187174   \n",
      "1895944  77.749970   0.390458   0.920621  3.378372   28.323000  2.199444   \n",
      "1895950  77.749974   0.389909   0.920853  4.538411   92.542000  2.193886   \n",
      "1895955  77.749977   0.392062   0.919939  4.544709   93.133003  2.190536   \n",
      "1895960  77.749981   0.385492   0.922711  4.604900   98.973000  2.191654   \n",
      "\n",
      "         log_Power  Coarse_Cluster  \n",
      "3         0.841567               0  \n",
      "9         0.792993               0  \n",
      "14        0.900161               0  \n",
      "20        0.858662               0  \n",
      "26        0.806476               0  \n",
      "...            ...             ...  \n",
      "1895938   2.299581               0  \n",
      "1895944   2.300583               0  \n",
      "1895950   2.312535               0  \n",
      "1895955   2.294553               0  \n",
      "1895960   2.301585               0  \n",
      "\n",
      "[340748 rows x 14 columns]\n",
      "\n",
      "\n",
      "======================================================================\n",
      "CLUSTER 1\n",
      "Total Pulses: 419396\n",
      "----------------------------------------------------------------------\n",
      "               TOA_us  PW_us  Freq_MHz  Power_dBm     DOA_deg  AC_Lat  \\\n",
      "0        2.620790e+02   5.03   9051.28     -16.57  354.555952    12.0   \n",
      "2        8.624440e+02   5.03   9050.63     -16.50  355.359951    12.0   \n",
      "6        1.513464e+03   5.04   9050.87     -16.55  353.465736    12.0   \n",
      "11       2.213906e+03   5.04   9048.64     -16.53  354.939173    12.0   \n",
      "15       2.809536e+03   5.00   9049.40     -16.45  349.684528    12.0   \n",
      "...               ...    ...       ...        ...         ...     ...   \n",
      "1895947  2.725968e+08   4.99   9050.72     -20.21  182.895075    12.0   \n",
      "1895952  2.725974e+08   5.03   9050.72     -19.96  183.516339    12.0   \n",
      "1895956  2.725981e+08   5.07   9049.63     -20.02  186.362066    12.0   \n",
      "1895961  2.725987e+08   4.98   9050.49     -20.14  183.796676    12.0   \n",
      "1895966  2.725994e+08   4.96   9051.02     -19.97  185.968893    12.0   \n",
      "\n",
      "            AC_Lon  AOA_sin_w  AOA_cos_w      log_dTOA     TOA_gap    log_PW  \\\n",
      "0        76.500000  -0.094874   0.995489  9.999995e-07    0.000001  1.796747   \n",
      "2        76.500003  -0.080896   0.996723  3.453821e+00   30.621000  1.796747   \n",
      "6        76.500006  -0.113797   0.993504  5.671142e+00  289.365997  1.798404   \n",
      "11       76.500009  -0.088213   0.996102  5.278977e+00  195.169006  1.798404   \n",
      "15       76.500012  -0.179068   0.983837  4.400051e+00   80.455002  1.791759   \n",
      "...            ...        ...        ...           ...         ...       ...   \n",
      "1895947  77.749972  -0.050507  -0.998724  5.611875e+00  272.657013  1.790091   \n",
      "1895952  77.749975  -0.061333  -0.998117  4.651309e+00  103.722000  1.796747   \n",
      "1895956  77.749978  -0.110811  -0.993842  5.715504e+00  302.536987  1.803359   \n",
      "1895961  77.749981  -0.066216  -0.997805  4.646159e+00  103.183998  1.788421   \n",
      "1895966  77.749984  -0.103989  -0.994578  4.152142e+00   62.570000  1.785070   \n",
      "\n",
      "         log_Power  Coarse_Cluster  \n",
      "0         2.513656               1  \n",
      "2         2.519308               1  \n",
      "6         2.515274               1  \n",
      "11        2.516890               1  \n",
      "15        2.523326               1  \n",
      "...            ...             ...  \n",
      "1895947   1.345472               1  \n",
      "1895952   1.408545               1  \n",
      "1895956   1.393766               1  \n",
      "1895961   1.363537               1  \n",
      "1895966   1.406097               1  \n",
      "\n",
      "[419391 rows x 14 columns]\n",
      "\n",
      "\n",
      "======================================================================\n",
      "CLUSTER 2\n",
      "Total Pulses: 454330\n",
      "----------------------------------------------------------------------\n",
      "               TOA_us  PW_us  Freq_MHz  Power_dBm    DOA_deg  AC_Lat  \\\n",
      "4        1.181078e+03   5.04   9050.51     -26.66   5.352844    12.0   \n",
      "8        1.780605e+03   4.94   9050.76     -26.71   5.363046    12.0   \n",
      "12       2.377849e+03   5.00   9050.14     -26.59   5.306258    12.0   \n",
      "17       2.974366e+03   4.97   9050.48     -26.62   5.232279    12.0   \n",
      "21       3.577970e+03   4.95   9049.93     -26.61   5.324049    12.0   \n",
      "...               ...    ...       ...        ...        ...     ...   \n",
      "1895949  2.725969e+08   5.04   9049.55     -14.12  22.839660    12.0   \n",
      "1895953  2.725975e+08   5.03   9050.89     -14.06  23.334134    12.0   \n",
      "1895958  2.725981e+08   4.91   9049.62     -14.15  23.505538    12.0   \n",
      "1895962  2.725987e+08   4.98   9049.87     -14.04  23.327238    12.0   \n",
      "1895965  2.725993e+08   5.05   9052.31     -14.16  23.288983    12.0   \n",
      "\n",
      "            AC_Lon  AOA_sin_w  AOA_cos_w  log_dTOA     TOA_gap    log_PW  \\\n",
      "4        76.500003   0.093289   0.995639  4.159883   63.063999  1.798404   \n",
      "8        76.500005   0.093466   0.995622  5.090666  161.498001  1.781709   \n",
      "12       76.500008   0.092479   0.995715  5.105600  163.942993  1.791759   \n",
      "17       76.500011   0.091194   0.995833  5.038853  153.292999  1.786747   \n",
      "21       76.500014   0.092789   0.995686  3.866628   46.780998  1.783391   \n",
      "...            ...        ...        ...       ...         ...       ...   \n",
      "1895949  77.749973   0.388154   0.921595  2.031826    6.628000  1.798404   \n",
      "1895953  77.749976   0.396093   0.918211  4.769464  116.856003  1.796747   \n",
      "1895958  77.749979   0.398838   0.917022  2.763548   14.856000  1.776646   \n",
      "1895962  77.749982   0.395982   0.918258  2.424183   10.293000  1.788421   \n",
      "1895965  77.749984   0.395369   0.918522  1.770195    4.872000  1.800058   \n",
      "\n",
      "         log_Power  Coarse_Cluster  \n",
      "4         0.815365               2  \n",
      "8         0.792993               2  \n",
      "12        0.845868               2  \n",
      "17        0.832909               2  \n",
      "21        0.837248               2  \n",
      "...            ...             ...  \n",
      "1895949   2.295560               2  \n",
      "1895953   2.301585               2  \n",
      "1895958   2.292535               2  \n",
      "1895962   2.303585               2  \n",
      "1895965   2.291524               2  \n",
      "\n",
      "[454325 rows x 14 columns]\n",
      "\n",
      "\n",
      "======================================================================\n",
      "CLUSTER 3\n",
      "Total Pulses: 681510\n",
      "----------------------------------------------------------------------\n",
      "               TOA_us  PW_us  Freq_MHz  Power_dBm    DOA_deg  AC_Lat  \\\n",
      "5        1.224098e+03   5.00   9098.07     -26.14   3.805426    12.0   \n",
      "7        1.619107e+03   5.03   9099.20     -26.11   3.807258    12.0   \n",
      "10       2.018737e+03   4.98   9100.52     -26.09   3.799621    12.0   \n",
      "13       2.420182e+03   5.00   9099.99     -26.10   3.804861    12.0   \n",
      "16       2.821073e+03   5.01   9099.97     -26.08   3.782178    12.0   \n",
      "...               ...    ...       ...        ...        ...     ...   \n",
      "1895963  2.725989e+08   4.94   9099.25     -11.19  21.954486    12.0   \n",
      "1895964  2.725993e+08   4.99   9101.51     -11.09  21.496090    12.0   \n",
      "1895968  2.725997e+08   5.05   9100.45     -11.10  21.666891    12.0   \n",
      "1895971  2.726001e+08   5.03   9099.59     -11.14  21.767299    12.0   \n",
      "1895973  2.726005e+08   4.96   9099.16     -11.19  21.781592    12.0   \n",
      "\n",
      "            AC_Lon  AOA_sin_w  AOA_cos_w  log_dTOA     TOA_gap    log_PW  \\\n",
      "5        76.500003   0.066368   0.997795  3.784644   43.020000  1.791759   \n",
      "7        76.500005   0.066400   0.997793  4.669487  105.642998  1.796747   \n",
      "10       76.500007   0.066267   0.997802  4.509518   89.877998  1.788421   \n",
      "13       76.500009   0.066359   0.997796  3.768914   42.333000  1.791759   \n",
      "16       76.500010   0.065964   0.997822  2.528684   11.537000  1.793425   \n",
      "...            ...        ...        ...       ...         ...       ...   \n",
      "1895963  77.749983   0.373870   0.927481  5.235990  186.914993  1.781709   \n",
      "1895964  77.749984   0.366438   0.930443  5.989174  398.084991  1.790091   \n",
      "1895968  77.749986   0.369210   0.929346  5.693739  296.002014  1.800058   \n",
      "1895971  77.749988   0.370838   0.928698  3.696500   39.306000  1.796747   \n",
      "1895973  77.749990   0.371070   0.928605  5.744134  311.352997  1.785070   \n",
      "\n",
      "         log_Power  Coarse_Cluster  \n",
      "5         1.022451               3  \n",
      "7         1.033184               3  \n",
      "10        1.040277               3  \n",
      "13        1.036737               3  \n",
      "16        1.043804               3  \n",
      "...            ...             ...  \n",
      "1895963   2.554122               3  \n",
      "1895964   2.561868               3  \n",
      "1895968   2.561096               3  \n",
      "1895971   2.558002               3  \n",
      "1895973   2.554122               3  \n",
      "\n",
      "[681505 rows x 14 columns]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CELL 4.5: PRINT FIRST 5 AND LAST 5 ROWS OF EACH CLUSTER\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\nInspecting clusters...\\n\")\n",
    "\n",
    "if \"Coarse_Cluster\" not in df.columns:\n",
    "    raise RuntimeError(\"Coarse_Cluster column not found. Run Cell 4 first.\")\n",
    "\n",
    "unique_clusters = sorted(df[\"Coarse_Cluster\"].unique())\n",
    "\n",
    "for cluster_id in unique_clusters:\n",
    "    \n",
    "    if cluster_id == -1:\n",
    "        continue  # Skip noise (optional)\n",
    "\n",
    "    cluster_df = df[df[\"Coarse_Cluster\"] == cluster_id].copy()\n",
    "\n",
    "    if cluster_df.empty:\n",
    "        continue\n",
    "\n",
    "    cluster_df.sort_values(\"TOA_us\", inplace=True)\n",
    "\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"CLUSTER {cluster_id}\")\n",
    "    print(f\"Total Pulses: {len(cluster_df)}\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "    print(cluster_df.head(-5))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ccc8bf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55f316be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading clustered PDW file...\n",
      "\n",
      "==============================\n",
      "PROCESSING COARSE CLUSTER 0\n",
      "==============================\n",
      "Detected PRI Type: Fixed\n",
      "Frame PRI ≈ 800.000\n",
      "Sub PRIs: [np.float64(800.0)]\n",
      "\n",
      "==============================\n",
      "PROCESSING COARSE CLUSTER 1\n",
      "==============================\n",
      "Detected PRI Type: Staggered\n",
      "Frame PRI ≈ 649.000\n",
      "Sub PRIs: [np.float64(599.0), np.float64(649.0), np.float64(699.0)]\n",
      "\n",
      "==============================\n",
      "PROCESSING COARSE CLUSTER 2\n",
      "==============================\n",
      "Detected PRI Type: Fixed\n",
      "Frame PRI ≈ 600.000\n",
      "Sub PRIs: [np.float64(600.0)]\n",
      "\n",
      "==============================\n",
      "PROCESSING COARSE CLUSTER 3\n",
      "==============================\n",
      "Detected PRI Type: Fixed\n",
      "Frame PRI ≈ 399.000\n",
      "Sub PRIs: [np.float64(399.0)]\n",
      "\n",
      "FINAL EMITTER COUNT: 4\n",
      "\n",
      "Emitter Summary:\n",
      "   Emitter_ID  Cluster  Pulse_Count   PRI_Type  Frame_PRI  \\\n",
      "0           0        0       340752      Fixed      800.0   \n",
      "1           1        1       419395  Staggered      649.0   \n",
      "2           2        2       454329      Fixed      600.0   \n",
      "3           3        3       681509      Fixed      399.0   \n",
      "\n",
      "                Sub_PRIs  \n",
      "0                [800.0]  \n",
      "1  [599.0, 649.0, 699.0]  \n",
      "2                [600.0]  \n",
      "3                [399.0]  \n"
     ]
    }
   ],
   "source": [
    "# CELL 5: FAST PRI DE-INTERLEAVING (with correct stagger handling)\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "import gc\n",
    "\n",
    "print(\"Loading clustered PDW file...\")\n",
    "df = pd.read_parquet(\"pdw_clustered.parquet\")\n",
    "df[\"Fine_Cluster\"] = -1\n",
    "\n",
    "summary_rows = []\n",
    "emitter_id = 0\n",
    "\n",
    "# --------------------------\n",
    "# PRI peak detection\n",
    "# --------------------------\n",
    "def get_pri_candidates(toa, bin_us=1.0):\n",
    "    dtoa = np.diff(toa)\n",
    "    dtoa = dtoa[(dtoa > 2) & (dtoa < 8000)]\n",
    "    if len(dtoa) < 30:\n",
    "        return []\n",
    "\n",
    "    bins = np.arange(0, dtoa.max() + bin_us, bin_us)\n",
    "    hist, edges = np.histogram(dtoa, bins=bins)\n",
    "\n",
    "    peaks, _ = find_peaks(hist, prominence=np.max(hist)*0.30)\n",
    "    return edges[peaks]\n",
    "\n",
    "# --------------------------\n",
    "# Grouping close PRI values\n",
    "# --------------------------\n",
    "def group_pri_candidates(pri_raw, window=20):\n",
    "    if len(pri_raw) == 0:\n",
    "        return []\n",
    "\n",
    "    pri_raw = np.sort(pri_raw)\n",
    "    groups = []\n",
    "    cur = [pri_raw[0]]\n",
    "\n",
    "    for p in pri_raw[1:]:\n",
    "        if abs(p - cur[-1]) <= window:\n",
    "            cur.append(p)\n",
    "        else:\n",
    "            groups.append(cur)\n",
    "            cur = [p]\n",
    "\n",
    "    groups.append(cur)\n",
    "    return [np.mean(g) for g in groups]\n",
    "\n",
    "# --------------------------\n",
    "# Scoring PRI strength\n",
    "# --------------------------\n",
    "def score_pris(dtoa, pri_list, tol=0.10):\n",
    "    scores = []\n",
    "    for pri in pri_list:\n",
    "        lo, hi = pri*(1-tol), pri*(1+tol)\n",
    "        count = np.sum((dtoa >= lo) & (dtoa <= hi))\n",
    "        scores.append((pri, count))\n",
    "\n",
    "    max_count = max(s for _, s in scores)\n",
    "    return [(p, s) for p, s in scores if s > max_count*0.25]\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# MAIN LOOP\n",
    "# --------------------------\n",
    "coarse_vals = sorted(df[\"Coarse_Cluster\"].unique())\n",
    "fine_cluster_id = 0\n",
    "\n",
    "for c in coarse_vals:\n",
    "    if c == -1:\n",
    "        continue\n",
    "\n",
    "    print(\"\\n==============================\")\n",
    "    print(f\"PROCESSING COARSE CLUSTER {c}\")\n",
    "    print(\"==============================\")\n",
    "\n",
    "    sub = df[df[\"Coarse_Cluster\"] == c].copy()\n",
    "    toa = np.sort(sub[\"TOA_us\"].to_numpy())\n",
    "\n",
    "    if len(toa) < 20:\n",
    "        pri_type = \"Unknown\"\n",
    "        df.loc[sub.index, \"Fine_Cluster\"] = fine_cluster_id\n",
    "\n",
    "        summary_rows.append([\n",
    "            emitter_id, c, len(sub),\n",
    "            pri_type, None, []\n",
    "        ])\n",
    "        emitter_id += 1\n",
    "        fine_cluster_id += 1\n",
    "        continue\n",
    "\n",
    "    # Step 1\n",
    "    pri_raw = get_pri_candidates(toa)\n",
    "\n",
    "    # Step 2\n",
    "    pri_groups = group_pri_candidates(pri_raw)\n",
    "\n",
    "    # Step 3\n",
    "    dtoa = np.diff(toa)\n",
    "    scored = score_pris(dtoa, pri_groups)\n",
    "\n",
    "    if len(scored) == 0:\n",
    "        df.loc[sub.index, \"Fine_Cluster\"] = fine_cluster_id\n",
    "        summary_rows.append([\n",
    "            emitter_id, c, len(sub), \"Unknown\", None, []\n",
    "        ])\n",
    "        emitter_id += 1\n",
    "        fine_cluster_id += 1\n",
    "        continue\n",
    "\n",
    "    # Extract PRI list and frame PRI\n",
    "    final_pris = sorted([p for p, _ in scored])\n",
    "    frame_pri = np.mean(final_pris)\n",
    "\n",
    "    # PRI type classification\n",
    "    if len(final_pris) == 1:\n",
    "        pri_type = \"Fixed\"\n",
    "    else:\n",
    "        pri_type = \"Staggered\"\n",
    "\n",
    "    print(f\"Detected PRI Type: {pri_type}\")\n",
    "    print(f\"Frame PRI ≈ {frame_pri:.3f}\")\n",
    "    print(f\"Sub PRIs: {final_pris}\")\n",
    "\n",
    "    # Assign ALL pulses to ONE fine cluster for staggered / fixed\n",
    "    # ------------------------------------------------------------\n",
    "    mask = np.zeros(len(dtoa), dtype=bool)\n",
    "\n",
    "    for pri in final_pris:\n",
    "        lo, hi = pri*0.85, pri*1.15\n",
    "        mask |= (dtoa >= lo) & (dtoa <= hi)\n",
    "\n",
    "    assigned_idx = sub.index[np.where(mask)[0]]\n",
    "    df.loc[assigned_idx, \"Fine_Cluster\"] = fine_cluster_id\n",
    "\n",
    "    summary_rows.append([\n",
    "        emitter_id,\n",
    "        c,\n",
    "        len(assigned_idx),\n",
    "        pri_type,\n",
    "        float(frame_pri),\n",
    "        final_pris\n",
    "    ])\n",
    "\n",
    "    emitter_id += 1\n",
    "    fine_cluster_id += 1\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# SAVE\n",
    "# --------------------------\n",
    "summary_df = pd.DataFrame(summary_rows, columns=[\n",
    "    \"Emitter_ID\", \"Cluster\", \"Pulse_Count\",\n",
    "    \"PRI_Type\", \"Frame_PRI\", \"Sub_PRIs\"\n",
    "])\n",
    "\n",
    "print(\"\\nFINAL EMITTER COUNT:\", len(summary_df))\n",
    "print(\"\\nEmitter Summary:\")\n",
    "print(summary_df)\n",
    "\n",
    "OUTPUT = \"pdw_final_clusters.parquet\"\n",
    "df.to_parquet(OUTPUT, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c61b33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "FINAL RADAR PARAMETER SUMMARY\n",
      "==============================\n",
      "\n",
      " Emitter_ID  Coarse_Cluster   RF_MHz  PW_us  Power_dBm  PRI_Type  Frame_PRI_us         PRI_Values_us  Pulse_Count\n",
      "          0               0 9000.000    8.0    -21.719     Fixed         800.0               [800.0]       340752\n",
      "          1               1 9050.001    5.0    -10.976 Staggered         649.0 [599.0, 649.0, 699.0]       419395\n",
      "          2               2 9049.997    5.0    -21.768     Fixed         600.0               [600.0]       454329\n",
      "          3               3 9100.002    5.0    -20.615     Fixed         399.0               [399.0]       681509\n",
      "\n",
      "===================================\n",
      "TOTAL RADARS DETECTED: 4\n",
      "===================================\n"
     ]
    }
   ],
   "source": [
    "# CELL 6: FINAL RADAR SUMMARY REPORT (Optimized + Tabular)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"\\n==============================\")\n",
    "print(\"FINAL RADAR PARAMETER SUMMARY\")\n",
    "print(\"==============================\\n\")\n",
    "\n",
    "# summary_df was produced in Cell 5 as the Emitter Summary\n",
    "emitter_summary = summary_df.copy()\n",
    "\n",
    "# Precompute cluster-level average parameters\n",
    "cluster_stats = (\n",
    "    df.groupby(\"Coarse_Cluster\")[[\"Freq_MHz\", \"PW_us\", \"Power_dBm\"]]\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "final_rows = []\n",
    "\n",
    "for row in emitter_summary.itertuples(index=False):\n",
    "\n",
    "    emitter_id   = row.Emitter_ID\n",
    "    cluster_id   = row.Cluster\n",
    "    pri_type     = row.PRI_Type\n",
    "    frame_pri    = row.Frame_PRI\n",
    "    sub_pris     = row.Sub_PRIs\n",
    "\n",
    "    # Pull RF/PW/Power statistics for this cluster\n",
    "    if cluster_id in cluster_stats.index:\n",
    "        stats = cluster_stats.loc[cluster_id]\n",
    "        rf_mhz   = round(stats[\"Freq_MHz\"], 3)\n",
    "        pw_us    = round(stats[\"PW_us\"], 3)\n",
    "        power_db = round(stats[\"Power_dBm\"], 3)\n",
    "    else:\n",
    "        # Fallback (should not occur)\n",
    "        rf_mhz, pw_us, power_db = None, None, None\n",
    "\n",
    "    # Ensure PRI list formatting\n",
    "    if isinstance(sub_pris, (list, np.ndarray)):\n",
    "        pri_values = np.round(sub_pris, 3).tolist()\n",
    "    else:\n",
    "        pri_values = []\n",
    "\n",
    "    # Handle missing frame PRI\n",
    "    frame_pri_val = round(frame_pri, 3) if frame_pri is not None else None\n",
    "\n",
    "    final_rows.append({\n",
    "        \"Emitter_ID\": emitter_id,\n",
    "        \"Coarse_Cluster\": cluster_id,\n",
    "        \"RF_MHz\": rf_mhz,\n",
    "        \"PW_us\": pw_us,\n",
    "        \"Power_dBm\": power_db,\n",
    "        \"PRI_Type\": pri_type,\n",
    "        \"Frame_PRI_us\": frame_pri_val,\n",
    "        \"PRI_Values_us\": pri_values,\n",
    "        \"Pulse_Count\": row.Pulse_Count\n",
    "    })\n",
    "\n",
    "final_df = pd.DataFrame(final_rows)\n",
    "\n",
    "# Display formatted table\n",
    "print(final_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n===================================\")\n",
    "print(\"TOTAL RADARS DETECTED:\", len(final_df))\n",
    "print(\"===================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8d05e6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "AOA GEO-LOCALIZATION (BODY DOA FIXED)\n",
      "==============================\n",
      "\n",
      "==============================\n",
      "LOCALIZATION COMPLETE\n",
      "==============================\n",
      "   Cluster_ID   Latitude  Longitude  Pulse_Count\n",
      "0           1  12.048834  76.998925       419396\n",
      "1           0  11.848987  78.107243       340753\n",
      "2           2  11.848988  78.107237       454330\n",
      "3           3  11.899021  78.006173       681510\n",
      "\n",
      "TOTAL RADARS LOCALIZED: 4\n"
     ]
    }
   ],
   "source": [
    "# CELL 7: AOA-ONLY LOCALIZATION (WITH HEADING ESTIMATION)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"\\n==============================\")\n",
    "print(\"AOA GEO-LOCALIZATION (BODY DOA FIXED)\")\n",
    "print(\"==============================\")\n",
    "\n",
    "df = pd.read_parquet(\"pdw_clustered.parquet\")\n",
    "\n",
    "# WGS84 constants\n",
    "a = 6378137.0\n",
    "e2 = 6.69437999014e-3\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1️⃣ Compute Aircraft Heading from Motion\n",
    "# ------------------------------------------------------------\n",
    "def compute_heading(lat, lon):\n",
    "\n",
    "    lat = np.radians(lat)\n",
    "    lon = np.radians(lon)\n",
    "\n",
    "    dlon = np.diff(lon)\n",
    "    x = np.sin(dlon) * np.cos(lat[1:])\n",
    "    y = np.cos(lat[:-1]) * np.sin(lat[1:]) - \\\n",
    "        np.sin(lat[:-1]) * np.cos(lat[1:]) * np.cos(dlon)\n",
    "\n",
    "    heading = np.degrees(np.arctan2(x, y))\n",
    "    heading = (heading + 360) % 360\n",
    "\n",
    "    # Pad first element\n",
    "    heading = np.insert(heading, 0, heading[0])\n",
    "\n",
    "    return heading\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2️⃣ Geodetic -> ECEF\n",
    "# ------------------------------------------------------------\n",
    "def geodetic_to_ecef(lat, lon, alt=0):\n",
    "\n",
    "    lat = np.radians(lat)\n",
    "    lon = np.radians(lon)\n",
    "\n",
    "    N = a / np.sqrt(1 - e2 * np.sin(lat)**2)\n",
    "\n",
    "    X = (N + alt) * np.cos(lat) * np.cos(lon)\n",
    "    Y = (N + alt) * np.cos(lat) * np.sin(lon)\n",
    "    Z = (N * (1 - e2) + alt) * np.sin(lat)\n",
    "\n",
    "    return np.stack([X, Y, Z], axis=-1)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3️⃣ ENU -> ECEF Conversion\n",
    "# ------------------------------------------------------------\n",
    "def enu_to_ecef(u_enu, lat, lon):\n",
    "\n",
    "    lat = np.radians(lat)\n",
    "    lon = np.radians(lon)\n",
    "\n",
    "    sin_lat = np.sin(lat)\n",
    "    cos_lat = np.cos(lat)\n",
    "    sin_lon = np.sin(lon)\n",
    "    cos_lon = np.cos(lon)\n",
    "\n",
    "    t = np.array([\n",
    "        [-sin_lon, -sin_lat*cos_lon,  cos_lat*cos_lon],\n",
    "        [ cos_lon, -sin_lat*sin_lon,  cos_lat*sin_lon],\n",
    "        [ 0,        cos_lat,          sin_lat]\n",
    "    ])\n",
    "\n",
    "    return (t @ u_enu.T).T\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4️⃣ Triangulation Solver\n",
    "# ------------------------------------------------------------\n",
    "def triangulate(P, U):\n",
    "\n",
    "    A = np.zeros((3,3))\n",
    "    b = np.zeros(3)\n",
    "    I = np.eye(3)\n",
    "\n",
    "    for i in range(len(P)):\n",
    "        u = U[i].reshape(3,1)\n",
    "        Pi = P[i]\n",
    "\n",
    "        Ai = I - u @ u.T\n",
    "        A += Ai\n",
    "        b += Ai @ Pi\n",
    "\n",
    "    try:\n",
    "        X = np.linalg.solve(A, b)\n",
    "    except np.linalg.LinAlgError:\n",
    "        return None\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5️⃣ ECEF -> Geodetic\n",
    "# ------------------------------------------------------------\n",
    "def ecef_to_geodetic(X, Y, Z):\n",
    "\n",
    "    lon = np.arctan2(Y, X)\n",
    "    p = np.sqrt(X**2 + Y**2)\n",
    "    lat = np.arctan2(Z, p * (1 - e2))\n",
    "\n",
    "    for _ in range(5):\n",
    "        N = a / np.sqrt(1 - e2 * np.sin(lat)**2)\n",
    "        lat = np.arctan2(Z + e2 * N * np.sin(lat), p)\n",
    "\n",
    "    return np.degrees(lat), np.degrees(lon)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6️⃣ LOCALIZE EACH CLUSTER\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "localized_emitters = []\n",
    "\n",
    "for cid in df[\"Coarse_Cluster\"].unique():\n",
    "\n",
    "    if cid == -1:\n",
    "        continue\n",
    "\n",
    "    cluster = df[df[\"Coarse_Cluster\"] == cid].sort_values(\"TOA_us\")\n",
    "\n",
    "    if len(cluster) < 20:\n",
    "        continue\n",
    "\n",
    "    lat = cluster[\"AC_Lat\"].values\n",
    "    lon = cluster[\"AC_Lon\"].values\n",
    "    doa_body = cluster[\"DOA_deg\"].values\n",
    "\n",
    "    # Compute aircraft heading\n",
    "    heading = compute_heading(lat, lon)\n",
    "\n",
    "    # Convert body DOA -> global azimuth\n",
    "    azimuth = (heading + doa_body) % 360\n",
    "\n",
    "    # Build ENU unit vectors\n",
    "    az_rad = np.radians(azimuth)\n",
    "\n",
    "    u_enu = np.stack([\n",
    "        np.sin(az_rad),   # East\n",
    "        np.cos(az_rad),   # North\n",
    "        np.zeros_like(az_rad)\n",
    "    ], axis=-1)\n",
    "\n",
    "    # Convert aircraft positions to ECEF\n",
    "    P = geodetic_to_ecef(lat, lon)\n",
    "\n",
    "    # Convert ENU vectors to ECEF\n",
    "    U = np.array([\n",
    "        enu_to_ecef(u_enu[i], lat[i], lon[i])\n",
    "        for i in range(len(u_enu))\n",
    "    ])\n",
    "\n",
    "    # Solve intersection\n",
    "    X = triangulate(P, U)\n",
    "\n",
    "    if X is None:\n",
    "        continue\n",
    "\n",
    "    est_lat, est_lon = ecef_to_geodetic(X[0], X[1], X[2])\n",
    "\n",
    "    localized_emitters.append({\n",
    "        \"Cluster_ID\": cid,\n",
    "        \"Latitude\": round(est_lat, 6),\n",
    "        \"Longitude\": round(est_lon, 6),\n",
    "        \"Pulse_Count\": len(cluster)\n",
    "    })\n",
    "\n",
    "\n",
    "radar_locations = pd.DataFrame(localized_emitters)\n",
    "\n",
    "print(\"\\n==============================\")\n",
    "print(\"LOCALIZATION COMPLETE\")\n",
    "print(\"==============================\")\n",
    "print(radar_locations)\n",
    "print(\"\\nTOTAL RADARS LOCALIZED:\", len(radar_locations))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
